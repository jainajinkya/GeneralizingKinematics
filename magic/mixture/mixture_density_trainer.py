import os
import sys
import time

import numpy as np
import pandas as pd
import torch
import matplotlib

matplotlib.use('Agg')
from matplotlib import pyplot as plt

import GeneralizingKinematics.magic.mixture.mdn as mdn
from GeneralizingKinematics.magic.mixture.utils import *


class MDNTrainer(object):
    """ Trains a mixture density network to predict object kinematics  """

    def __init__(self,
                 model,
                 train_loader,
                 test_loader,
                 optimizer,
                 epochs,
                 name,
                 test_freq,
                 device,
                 obj='microwave',
                 ndof=1):
        super(MDNTrainer, self).__init__()
        self.model = model
        self.trainloader = train_loader
        self.testloader = test_loader
        self.optimizer = optimizer
        self.criterion = mdn.mdn_loss
        self.epochs = epochs
        self.name = name
        self.test_freq = test_freq
        self.obj = obj
        self.ndof = ndof

        self.normalize = True
        self.losses = []
        self.tlosses = []

        # float model as push to GPU/CPU
        self.device = device
        self.model.float().to(self.device)

    def train(self):
        best_tloss = 1e8
        for epoch in range(self.epochs):
            sys.stdout.flush()
            loss = self.train_epoch(epoch)
            self.losses.append(loss)
            if epoch % self.test_freq == 0:
                tloss = self.test_epoch(epoch)
                self.tlosses.append(tloss)
                self.plot_losses()

                if tloss < best_tloss:
                    print('saving model.')
                    net_fname = 'models/' + str(self.name) + '.net'
                    torch.save(self.model.state_dict(), net_fname)
                    best_tloss = tloss

        # plot losses one more time
        self.plot_losses()

        # re-load the best state dictionary that was saved earlier.
        self.model.load_state_dict(torch.load(net_fname, map_location='cpu'))

        return self.model

    def train_epoch(self, epoch):
        # print('train epoch')
        start = time.time()
        running_loss = 0
        batches_per_dataset = len(self.trainloader.dataset) / self.trainloader.batch_size
        for i, X in enumerate(self.trainloader):
            self.optimizer.zero_grad()
            depth, labels = X['depth'].to(self.device), X['label'].to(self.device)

            #
            # depth[0,0,0,0]=1.0
            # plt.imshow(depth[0,0].numpy())
            # plt.show()

            pi, sigma, mu = self.model(depth)
            loss = self.criterion(pi, sigma, mu, labels)
            if loss.data == -float('inf'):
                print('inf loss caught, not backpropping')
                running_loss += -1000
            else:
                loss.backward()
                self.optimizer.step()
                running_loss += loss.item()

        euc = self.analyze_shape_loss(labels, pi, sigma, mu)
        # euc = torch.tensor([1,2,3]).float()
        stop = time.time()
        print('Epoch %s -  Train  Loss: %.5f Euc. Axis Error: %.3f Time: %.5f' % (str(epoch).zfill(3),
                                                                                  running_loss / batches_per_dataset,
                                                                                  euc.mean(), stop - start))
        return running_loss / batches_per_dataset

    def test_epoch(self, epoch):
        # print('test epoch')
        start = time.time()
        running_loss = 0
        batches_per_dataset = len(self.testloader.dataset) / self.testloader.batch_size
        with torch.no_grad():
            for i, X in enumerate(self.testloader):
                depth, labels = X['depth'].to(self.device), X['label'].to(self.device)
                pi, sigma, mu = self.model(depth)
                loss = self.criterion(pi, sigma, mu, labels)
                running_loss += loss.item()

        # print('pi', pi.shape)
        # print('sigma', sigma.shape)
        # print('mu', mu.shape)
        euc = self.analyze_shape_loss(labels, pi, sigma, mu)
        # try:
        # 	euc = self.analyze_shape_loss(labels, pi, sigma, mu)
        # except Exception as e:
        # 	print('cuda sampling error')
        # 	euc=torch.tensor([-1]).float()

        stop = time.time()
        print('Epoch %s -  Test  Loss: %.5f Euc. Axis Error: %.3f Time: %.5f' % (str(epoch).zfill(3),
                                                                                 running_loss / batches_per_dataset,
                                                                                 euc.mean(), stop - start))
        return running_loss / batches_per_dataset

    def analyze_shape_loss(self, labels, pi, sigma, mu):

        # draw samples from MoG defined by parameters
        output = mdn.sample(pi, sigma, mu)

        # expand labels and output back to full size
        output = expand_labels(self.trainloader.dataset.full_labels[:len(labels)],
                               output,
                               self.trainloader.dataset.keep_columns,
                               self.trainloader.dataset.one_columns)

        labels = expand_labels(self.trainloader.dataset.full_labels[:len(labels)],
                               labels,
                               self.trainloader.dataset.keep_columns,
                               self.trainloader.dataset.one_columns)

        # interpret and convert to real.
        ground_truth_params = convert_dict_to_real(interpret_labels(labels, self.ndof),
                                                   self.trainloader.dataset.bounds,
                                                   self.ndof)
        param_dict = convert_dict_to_real(interpret_labels(output, self.ndof),
                                          self.trainloader.dataset.bounds,
                                          self.ndof)
        real_axis = ground_truth_params['axis']
        real_net_axis = param_dict['axis']

        euc = euclidean_distance(real_axis[:, :, :3], real_net_axis[:, :, :3]) * 100.0
        return euc

    def plot_losses(self):
        os.makedirs("plots/" + self.name, exist_ok=True)
        x = np.arange(len(self.losses))
        tx = np.arange(0, len(self.losses), self.test_freq)
        plt.plot(x, np.array(self.losses), color='b', label='train')
        plt.plot(tx, np.array(self.tlosses), color='r', label='test')
        plt.legend()
        plt.xlabel('Epoch')
        plt.ylabel('Loss')
        plt.savefig('plots/' + self.name + '/curve.png')
        plt.close()
        np.save('plots/' + self.name + '/losses.npy', np.array(self.losses))
        np.save('plots/' + self.name + '/tlosses.npy', np.array(self.tlosses))
